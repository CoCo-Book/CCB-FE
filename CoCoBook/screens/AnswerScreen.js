// screens/AnswerScreen.js
// screens/AnswerScreen.js
import React, { useEffect, useRef, useState } from 'react';
import { View, Text, Image, TouchableOpacity, StyleSheet, ActivityIndicator, Alert, ImageBackground } from 'react-native';
import RNFS from 'react-native-fs';
import { startRecording, stopRecording } from '../hooks/useRecorder';
import { getPresignedUrl, uploadToS3 } from '../api/s3';
import { API, WS } from '../constants';
import { fetchJwtToken } from '../utils/getJwtToken';
import Sound from 'react-native-sound';

Sound.setCategory('Playback');

const AnswerScreen = ({ navigation, route }) => {
  const ws = useRef(null);
  const [status, setStatus] = useState('connecting');
  const [isRecording, setIsRecording] = useState(false);
  const [aiText, setAiText] = useState('ì„œë²„ ì—°ê²° ì¤‘...');
  const [greetingLoaded, setGreetingLoaded] = useState(false);
  const soundRef = useRef(null);
  // childName, age, interests, jwtTokenì€ route.paramsì—ì„œ ë°›ìŒ. jwtTokenì´ ì—†ìœ¼ë©´ fetchí•´ì„œ ì‚¬ìš©
  const { childName, age, interests, jwtToken: routeJwtToken } = route.params || {};
  const [jwtToken, setJwtToken] = useState(routeJwtToken || null);

  // JWT í† í°ì´ ì—†ìœ¼ë©´ fetch
  useEffect(() => {
    if (jwtToken) return;
    const getToken = async () => {
      const token = await fetchJwtToken();
      setJwtToken(token);
    };
    getToken();
  }, []);

   // WebSocket ì—°ê²°
   useEffect(() => {
    if (!jwtToken || !childName || !age || !interests) return;
    const queryParams = `child_name=${encodeURIComponent(childName)}&age=${age}&interests=${encodeURIComponent(interests.join(','))}&token=${jwtToken}`;
    const wsUrl = `${WS.BASE_URL}?${queryParams}`;
    ws.current = new WebSocket(wsUrl);

    ws.current.onopen = () => {
      setStatus('connected');
      console.log('âœ… WebSocket ì—°ê²°ë¨');
    };
    ws.current.onmessage = async (event) => {
      const msg = JSON.parse(event.data);
      console.log('ì„œë²„ ì‘ë‹µ ë°›ìŒ:', msg);
      setAiText(msg.text);

      if (msg.audio) {
        try {
          const path = `${RNFS.CachesDirectoryPath}/ai_audio.mp3`;
          await RNFS.writeFile(path, msg.audio, 'base64');
          if (soundRef.current) soundRef.current.release();
          soundRef.current = new Sound(path, '', (error) => {
            if (error) {
              console.log('ìŒì„± ë¡œë”© ì‹¤íŒ¨:', error);
              return;
            }
            console.log('ìŒì„± ë¡œë”© ì„±ê³µ, ì¬ìƒ ì‹œì‘');
            soundRef.current.play((success) => {
              if (success) {
                console.log('ìŒì„± ì¬ìƒ ì„±ê³µ');
              } else {
                console.log('ìŒì„± ì¬ìƒ ì‹¤íŒ¨');
              }
            });
          });
        } catch (e) {
          console.log('ì˜¤ë””ì˜¤ ì €ì¥/ì¬ìƒ ì‹¤íŒ¨:', e);
        }
      } else {
        console.log('ì„œë²„ì—ì„œ audio ë°ì´í„°ê°€ ì˜¤ì§€ ì•ŠìŒ');
      }
    };
    ws.current.onerror = (e) => {
      setStatus('error');
      console.error('WebSocket ì—ëŸ¬:', e.message);
    };
    ws.current.onclose = () => {
      setStatus('closed');
      console.log('WebSocket ì—°ê²° ì¢…ë£Œ');
    };
    return () => {
      if (ws.current) ws.current.close();
    };
  }, [jwtToken, childName, age, interests]);

  useEffect(() => {
    const start = async () => {
      const result = await startRecording();
      if (result) {
        setIsRecording(true);
      }
    };
    start();
  }, []);

  const handleStart = async () => {
    const result = await startRecording();
    if (result) {
      setIsRecording(true);
    }
  };

  const handleFinish = async () => {
    if (!isRecording) {
      Alert.alert('ì‹¤íŒ¨', 'ë…¹ìŒì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }
    const path = await stopRecording();
    setIsRecording(false);
    if (!path || path === 'Already stopped') {
      Alert.alert('ì‹¤íŒ¨', 'ë…¹ìŒ íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
      return;
    }
    try {
      const base64String = await RNFS.readFile(path, 'base64');
      // audio_chunk ë©”ì‹œì§€ë¡œ ì„œë²„ì— ì „ì†¡
      ws.current.send(
        JSON.stringify({
          type: 'audio_chunk',
          data: base64String,
          chunk_index: 1, // ë‹¨ì¼ chunkë¼ë©´ 1
          is_final: true,
        })
      );
      console.log('ìŒì„± ë°ì´í„°ê°€ ì„œë²„ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.');
      navigation.navigate('MakeStory2');
    } catch (err) {
      console.error('ğŸ”´ íŒŒì¼ì„ Base64ë¡œ ì½ê¸° ì‹¤íŒ¨:', err);
      Alert.alert('ì‹¤íŒ¨', 'íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì‚¬ìš´ë“œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (soundRef.current) {
        soundRef.current.release();
      }
    };
  }, []);

  useEffect(() => {
    let timeoutId = null;
    let isMounted = true;

    const fetchAiGreeting = async () => {
      try {
        const res = await fetch(`${API.BASE_URL}/api/start`);
        const data = await res.json();
        if (isMounted && !greetingLoaded) {
          setGreetingLoaded(true);
          setAiText(data.text);
        }
      } catch (e) {
        // ì—ëŸ¬ê°€ ë‚˜ë„ 5ì´ˆ ë™ì•ˆì€ aiTextë¥¼ ë°”ê¾¸ì§€ ì•ŠìŒ
      }
    };

    timeoutId = setTimeout(() => {
      if (isMounted && !greetingLoaded) {
        setAiText('ì„œë²„ ì—°ê²° ì‹¤íŒ¨');
      }
    }, 5000);

    fetchAiGreeting();

    return () => {
      isMounted = false;
      clearTimeout(timeoutId);
    };
  }, []);

  return (
    <View style={styles.bg}>
    {/* ìƒë‹¨ í°ìƒ‰ ì˜ì—­ + ë§í’ì„  (í™”ì‚´í‘œ ì—†ìŒ) */}
    <View style={styles.topWhite}>
      <View style={styles.bubbleWrap}>
        <View style={styles.bubble}>
          <Text style={styles.bubbleText}>... ë¶€ê¸°ê°€ ì´ì•¼ê¸°ë¥¼ ë“£ëŠ”ì¤‘ ...</Text>
        </View>
      </View>
    </View>
    {/* ê°€ìš´ë° ë°°ê²½ ì´ë¯¸ì§€ ì˜ì—­ */}
    <ImageBackground source={require('../assets/num3.png')} style={styles.centerBg}>
      <View style={styles.container}>
        {/* ì´ë¯¸ì§€ ì œê±°ë¨ */}
      </View>
    </ImageBackground>
    {/* í•˜ë‹¨ í°ìƒ‰ ì˜ì—­ + ë²„íŠ¼ 1ê°œ */}
    <View style={styles.bottomWhite}>
      <TouchableOpacity style={styles.button} onPress={() => navigation.navigate('MakeStory2')}>
        <Text style={styles.buttonText}>ëŒ€ë‹µì™„ë£Œ</Text>
      </TouchableOpacity>
    </View>
    </View>
  );
};

const styles = StyleSheet.create({
  bg: {
    flex: 1,
    backgroundColor: '#fff',
  },
  topWhite: {
    width: '100%',
    height: 90,
    backgroundColor: '#fff',
    justifyContent: 'flex-end',
    alignItems: 'center',
  },
  centerBg: {
    flex: 1,
    width: '100%',
    justifyContent: 'flex-start',
    alignItems: 'center',
  },
  container: {
    flex: 1,
    width: '100%',
    alignItems: 'center',
  },
  bubbleWrap: {
    width: '100%',
    alignItems: 'center',
    marginTop: 0,
    marginLeft: 0,
    marginBottom: 14,
  },
  bubble: {
    width: '90%',
    backgroundColor: '#fff',
    borderRadius: 10,
    borderWidth: 3,
    borderColor: '#4B662B',
    paddingVertical: 14,
    paddingHorizontal: 24,
    alignItems: 'flex-start',
    justifyContent: 'center',
  },
  bubbleText: {
    fontWeight: 'bold',
    fontSize: 16,
    color: '#222',
    textAlign: 'left',
  },
  bookImage: {
    width: 160,
    height: 120,
    resizeMode: 'contain',
    marginTop: 12,
    marginBottom: 0,
  },
  boogiImage: {
    width: 160,
    height: 160,
    resizeMode: 'contain',
    marginTop: -16,
    marginBottom: 0,
  },
  bottomWhite: {
    width: '100%',
    backgroundColor: '#fff',
    alignItems: 'center',
    paddingVertical: 24,
  },
  button: {
    backgroundColor: '#9ACA70',
    borderRadius: 14,
    paddingHorizontal: 32,
    paddingVertical: 10,
    minWidth: 120,
    height: 48,
    justifyContent: 'center',
    alignItems: 'center',
    marginHorizontal: 8,
  },
  buttonText: {
    color: '#fff',
    fontWeight: 'bold',
    fontSize: 20,
    letterSpacing: 2,
    textAlign: 'center',
    includeFontPadding: false,
    paddingVertical: 0,
  },
});

export default AnswerScreen;