// screens/AnswerScreen.js
import React, { useEffect, useRef, useState } from 'react';
import { View, Text, Image, TouchableOpacity, StyleSheet, ActivityIndicator, Alert } from 'react-native';
import RNFS from 'react-native-fs';
import { startRecording, stopRecording } from '../hooks/useRecorder';
import { getPresignedUrl, uploadToS3 } from '../api/s3';
import { API, WS } from '../constants';
import { WS_AUTH_TOKEN } from '@env';

const AnswerScreen = ({ navigation, route }) => {
  const ws = useRef(null);
  const [status, setStatus] = useState('connecting');
  const [isRecording, setIsRecording] = useState(false);

  useEffect(() => {
    const { childName, age, interests } = route.params;
    const queryParams = `child_name=${encodeURIComponent(childName)}&age=${age}&interests=${encodeURIComponent(interests.join(','))}&token=${WS_AUTH_TOKEN}`;
    const wsUrl = `${WS.BASE_URL}?${queryParams}`;

    ws.current = new WebSocket(wsUrl);

    ws.current.onopen = () => {
      console.log('âœ… WebSocket ì—°ê²°ë¨');
      setStatus('connected');
    };

    ws.current.onmessage = (event) => {
      const msg = JSON.parse(event.data);
      console.log('ì„œë²„ ì‘ë‹µ ë°›ìŒ:', msg);

      if (msg.type === 'ai_response') {
        navigation.navigate('MakeStory2', { aiResult: msg });
      }
    };

    ws.current.onerror = (e) => {
      console.error('WebSocket ì—ëŸ¬:', e.message);
      setStatus('error');
    };

    ws.current.onclose = () => {
      console.log('WebSocket ì—°ê²° ì¢…ë£Œ');
      setStatus('closed');
    };

    return () => {
      if (ws.current) {
        ws.current.close();
      }
    };
  }, []);

  useEffect(() => {
    const start = async () => {
      const result = await startRecording();
      if (result) {
        setIsRecording(true);
      }
    };
    start();
  }, []);

  const handleStart = async () => {
    const result = await startRecording();
    if (result) {
      setIsRecording(true);
    }
  };

  const handleFinish = async () => {
    if (!isRecording) {
      Alert.alert('ì‹¤íŒ¨', 'ë…¹ìŒì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }
    const path = await stopRecording();
    setIsRecording(false);

    if (!path || path === 'Already stopped') {
      Alert.alert('ì‹¤íŒ¨', 'ë…¹ìŒ íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
      return;
    }

    try {
      const base64String = await RNFS.readFile(path, 'base64');
      Alert.alert('ì„±ê³µ', `íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n${path}`);
      navigation.navigate('MakeStory2', {
        audioPath: path,
        base64: base64String,
      });
    } catch (err) {
      console.error('ğŸ”´ íŒŒì¼ì„ Base64ë¡œ ì½ê¸° ì‹¤íŒ¨:', err);
      Alert.alert('ì‹¤íŒ¨', 'íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  return (
    <View style={styles.container}>
      <Text style={styles.topText}>ë¶€ê¸°ì™€ ëŒ€í™”ë¥¼ í†µí•´ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•˜ì„¸ìš”!</Text>

      <ActivityIndicator size="large" color="#3e5d3d" style={{ marginVertical: 10 }} />

      <Image source={require('../assets/boogiwithbook.png')} style={styles.image} />

      <Text style={styles.bottomText}>ë¶€ê¸°ê°€ ì´ì•¼ê¸°ë¥¼ ë“£ëŠ”ì¤‘ ...</Text>

      <TouchableOpacity
        style={styles.button}
        onPress={handleFinish}
      >
        <Text style={styles.buttonText}>ëŒ€ë‹µ ì™„ë£Œ</Text>
      </TouchableOpacity>
    </View>
  );
};

export default AnswerScreen;

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#e8f6cc',
    alignItems: 'center',
    justifyContent: 'center',
    padding: 20,
  },
  topText: {
    fontSize: 12,
    color: '#4a4a4a',
    marginBottom: 10,
  },
  image: {
    width: 180,
    height: 180,
    resizeMode: 'contain',
    marginVertical: 20,
  },
  bottomText: {
    fontSize: 14,
    marginBottom: 20,
    color: '#3e3e3e',
  },
  button: {
    backgroundColor: '#9ACA70',
    paddingVertical: 10,
    paddingHorizontal: 25,
    borderRadius: 12,
  },
  buttonText: {
    color: 'white',
    fontWeight: 'bold',
  },
});